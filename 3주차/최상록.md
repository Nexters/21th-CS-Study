## 3주차

### 메모리 관리 전략~ 캐시의 지역성


👫 **메모리 관리 배경**

각각의 프로세스는 독립된 메모리 공간을 가짐

- 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 설정
- 프로세스가 합법적인 영역만을 접근하도록 보호하는것이 필요함

메모리 공간의 보호

- CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어짐

👫 **메모리 관리 기법 :** 스와핑

- 프로세스는 실행 도중 임시로 보조 기억장치로 보내졌다가 메모리로 되돌아 올 수 있음
- RR과 같은 우선순위 기반 스케줄링 알고리즘에 적용 가능
    - 낮은 우선순위 프로세스를 디스크로 스왑
    - 높은 우선순위 프로세스가 끝나면, 낮은 우선순위 플세스는 다시 메모리로 스왑
    - RAM으로 불러오는 과정을 Roll-in, 보조 기억장치로 내보내는 과정을 Swap-out이라고 함
- 전송 시간은 스왑될 메모리의 크기와 비례
    - 스왑 시간의 대부분이 디스크 전송시간이기 때문
    

**💦동적 메모리 할당 문제와 해결 방법**

**동적 메모리 할당 문제** : 일련의 공간들로 부터 n-바이트 블록을 요구하는것을 어떻게 만족시켜줄 것인가 결정하는 문제

위 문제에 대해 세가지 방식을 제안함

1. **최초 적합(first-fit)**
    - 첫 번째 사용 가능한 공간 할당
2. **최적 적합(best-fit)**
    - 사용 가능한 공간들 중에서 가장 작은 것을 선택
    - 리스트가 정렬되어있지 않으면 리스트 전체 검색
    - 많은 작은 공간들이 생성
3. **최악 적합(worst-fit)**
    - 가장 큰 공간을 선택
    - 리스트가 정렬되어 있지 않다면 리스트 전체 검색
    - 할당해 주고 남게 되는 공간은 충분히 커서 다른 프로세스를 위해 유용히 사용

**first-fit, best-fit이 worst-fit보다 더 효율적**

**단편화(Fragmentation)**

위와 같이 동적 메모리 할당을 반복하다 보면, 프로세스들 사이를 차지하는 메모리 틈 사이에 사용이 불가능할 정도의 자유 공간들이 늘어나게 되는 현상을 말함

- 외부 단편화 : 너무 작은 조각들로 여러 곳에 분산된 경우
    
    → **압축(compaction)을 통해 해결**
    
    - 모든 내용들을 한군데로 몰고 모든 자유 공간들을 다른 한군데로 몰아 큰 블록으로 생성(프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우)
- 내부 단편화: 일반적으로 메모리가 고정된 크기의 정수 배로 할당되어, 할당된 공간이 요구된 공간보다 약간 더 큰 경우

**세그멘테이션(Segmentation)**

서로 다른 크기의 논리적 단위인 세그먼트로 저장 하는것 

- 논리 주소를 두 개의 주소로 지정<segment number, offset>
- 세그먼트 테이블에 기준(base, 세그먼트의 시작 주소) 와 한계(limit, 세그먼트의 길이) 저장

**단점** : 서로 다른 크기의 세그먼트들이 메모리의 적재 및 제거되는 일이 반복되다 보니, 자유 공간들이 많은 수의 작은 조각들로 나누어지는 외부 단편화가 발생

**페이징(paging)**

논리 주소 공간이 연속적인 공간에 모여있어야 한다는 제약을 없애는 메모리 관리 방법

- 외부 단편화의 해결 방법인 “압축”을 해소하기 위한 방법론
- 물리 메모리는 **프레임(frame)이라 불리우는 같은 크기 블록으로 분할**
- 논리 메모리는 **페이지(page)라 불리는 같은 크기의 블록으로 분할**
- 모든 자유 프레임 리스트들은 추적 관리됨
- 논리 주소에서 물리 주소로 변환하는 **페이지 테이블(page table)** 필요

한 프로세스가 실행될 때, 프로세스의 페이지는 보조 메모리로부터 메인 메모리 프레임으로 들어가게 됨.

**단점**: 메모리가 고정된 크기의 정수 배로 할당되다 보니, 요구된 공간보다 할당된 공간이 약간 더 크게 되는 **내부 단편화 현상**이 나타난다.

<br><br>

### 🙆‍♀️가상 메모리

### **등장 배경**

프로그램 코드는 실행 시 메모리에 적재되어있어야 하지만, 전체 프로그램의 사용은 빈번하지 않았다. 따라서 전체 프로그램 코드가 동시에 필요하지 않게 된다.

가상 메모리는 프로그램의 일부만 메모리에 적재하고 실행할 수 있게 한다. 프로그램이 더이상 물리 메모리의 크기 제약을 받지 않고, 메모리를 덜 차지하게 된다. 또한 프로그램을 메모리에 적재하거나 스왑 시 더 적은 입출력을 필요로 하게 된다.

### **가상메모리**

프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법

- 실제의 물리 메모리와 사용자의 논리 메모리 개념을 분리한다.
- 물리 주소 공간보다 훨씬 큰 가상 주소 공간을 제공한다.이는 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공한다.

### **가상 메모리 공간**

프로세스가 메모리에 저장되는 논리적인 관점

- 0번지 주소부터 시작되는 연속적인 주소 공간
- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다.
- 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다.
- 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 하자. 하지만 실행까지에 필요한 메모리 공간`(Heap영역, Stack 영역, 코드, 데이터)`의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해할 수 있겠다.

### **요구 페이징**

프로세스 전체를 메모리에 적재하지 않고, 필요한 페이지만을 물리 메모리에 적재하는 것을 말한다.

- 사용되지 않을 페이지를 메모리로 가져오지 않음으로써 시간과 메모리 공간 낭비를 줄인다.
- **게으른 스와퍼(lazy swapper) :** 페이지가 필요하지 않으면 메모리에 적재하지 않는 것을 말한다. 페이지를 관리하는 스와퍼를 페이저(pager)라고 한다.

### **유효-무효 비트**

페이지가 메모리에 올라와 있는지 구별하기 위해 페이지 테이블에 유효-무효 비트를 표시함, 초기는 i로 표시

유효비트(v) : 페이지가 메모리에 있음

무효비트(i) : 페이지가 메모리에 없음

만약, 주소 변환 중 무효비트 i로 세트되어 있다면 페이지 부재(page fault)가 발생한다.

프로세스가 메모리에 올라와 있지 않는 페이지를 접근하는 경우 페이지 부재(page-fault) 트랩(trap)이 발생한다.

### **페이지 교체**

모든 메모리가 사용중이어서 빈 프레임이 없는 경우 페이지 교체가 이루어 진다.

### **페이지 교체 알고리즘**

새로운 페이지를 메모리로 가져오고, 사용중인 페이지 중 하나를 선택한다. 교체되는 페이지(victim)는 디스크에 저장한다.

- 수정된 페이지만을 디스크에 저장하여 페이지 전송 오버헤드를 줄인다.

### ****FIFO 페이지 교체****

가장 간단한 페이지 교체 알고리즘으로 FIFO(first-in first-out)의 흐름을 가진다. 즉, 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다는 것이다.

- 장점
    - 이해하기도 쉽고, 프로그램하기도 쉽다.
- 단점
    - 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있다(초기 변수 등)
    - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있다.
    - `Belady의 모순`: 프레임을 더 주었는데, 오히려 페이지 부재율은 더 증가하는 현상
    
![image](https://user-images.githubusercontent.com/70064912/182391256-fdd75ede-e0b7-47ba-b5ba-bcd97867ed0a.png)
    

### **LRU 페이지 교체(LRU Page Replacement)**

참조 횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다.

- 특징
    - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다
    - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.

### **LRU 근사 페이지 교체(LRU Approximation Page Replacement)**

하드웨어 오버헤드가 큰 LRU 교체 알고리즘을 보완한 알고리즘이다.

- 페이지가 사용된 순서는 모른다.
- 페이지 항목에 1비트 참조 비트를 사용한다.

### **MFU 페이지 교체(MFU Page Replacement)**

가장 작은 참조 횟수를 가진 페이지가 가장 최근에 참조된 것이고, 앞으로 사용될 것이라는 판단에 근거한다.

- 특징
    - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.

### **최적 페이지 교체(Optimal Page Replacement)**

`Belady의 모순`을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되었고, 모든 알고리즘보다 낮은 페이지 부재율을 보이며 `Belady의 모순`이 발생하지 않는다. 이 알고리즘의 핵심은 `앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`하는 것이다. 주로 비교 연구 목적을 위해 사용한다.

- 장점
    - 알고리즘 중 가장 낮은 페이지 부재율을 보장한다.
- 단점
    - 구현의 어려움이 있다. 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문이다.

<br><br>

### 캐시 메모리

하드웨어에 의해 자동 관리되는 작고, 빠른 SRAM-기반 메모리

- 자주 접근되어 사용되는 메모리의 블록들을 저장
- CPU는 먼저 캐시 메모리를 참조

### **지역성의 원리**

프로그램은 최근에 자신이 참조했던 메모리 주소 근처의 데이터나 명령어를 참조하려는 경향이 있음

**시간 지역성** : 최근에 참조했던 메모리 위치를 가까운 미래에 다시 참조할 가능성이 높음

**공간 지역성** : 한 메모리 위치가 참조되면 가까운 미래에 근처의 메모리 위치를 참조할 가능성이 높음

이러한 지역성의 원리를 사용하여, CPU가 어떤 데이터를 원할 것인지에 대한 적중률(Hit Rate)를 극대화 시킨다.

### **Caching line**

캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 `묶음`으로 저장하는 것.

 프로세스는 다양한 주소에 있는 데이터를 사용하므로 빈번하게 사용하는 데이터의 주소 또한 흩어져 있다. 따라서 캐시에 저장하는 데이터에는 데이터의 메모리 주소 등을 기록해 둔 태그를 달아놓을 필요가 있다. 이러한 태그들의 묶음을 캐싱 라인이라고 하고 메모리로부터 가져올 때도 캐싱 라인을 기준으로 가져온다. 종류로는 대표적으로 세 가지 방식이 존재한다.

1. Direct Map
    - 메모리 주소의 일부를 인덱스로 사용하여 관리하는 방식이다.
    - 같은 인덱스를 갖는 메모리가 인접하여 액세스 되는 경우 cache miss가 발생할 수 있음
2. Full Associative
    - 비어있는 캐시 메모리에 마음대로 주소를 저장하는 방법이다.
    - 어떠한 규칙이나 조건이 없으므로 특정 캐시 셋 내의 모든 블럭을 순차적으로 찾아야 한다.
3. Set Associative
    - 여러개의 Direct Mapped 방식으로 나누어 사용하는 방법이다.
